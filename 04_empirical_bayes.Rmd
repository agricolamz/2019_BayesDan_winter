---
title: "4. Эмпирическая байесовская оценка"
author: "Г. Мороз"
editor_options: 
  chunk_output_type: console
---

```{r child = 'preamble.Rmd'}
```

## 1. Эмпирическая байесовская оценка (Empirical Bayes Estimation)

Если наши данные представляют собой группировки независимых наблюдений, в которых мы предполагаем сходное значение оцениваемого параметра θ (доля *не* в куче рассказов Чехова, количество согласных в языках мира и т. д.), можно применять эмпирическую байесовскую оценку априорного распределения.

Эмпирическая байесовская оценка --- один из байесовских методов, в рамках которого:

* производят оценку априорного распределения вероятностей на основании имеющихся данных
* используют полученное априорное распределение для получение апостериорной оценки для каждого наблюдения

```{r}
chekhov <- read_tsv("https://raw.githubusercontent.com/agricolamz/2019_data_analysis_for_linguists/master/data/tidy_chekhov.tsv")
chekhov %>% 
  mutate(trunc_titles = str_trunc(titles, 25, side = "right"),
         average = n/n_words) ->
  chekhov
head(chekhov)
```

* 311 рассказов А. Чехова
* число слов в каждом рассказе
* 46610 уникальных слов в каждом рассказе

Наши данные:
```{r}
chekhov %>% 
  filter(word == "не") %>% 
  select(trunc_titles, word, average) %>% 
  ggplot(aes(average)) +
  geom_histogram(fill = "lightblue")+
  geom_density(color = "red")+
  theme_bw()+
  labs(title = 'Частотность слова "не" на основе 305 рассказов А. Чехова')
```

В данном случае, данные можно подогнать под бета распределение $Χ \sim Beta(α_0, β_0)$ (это далеко не всегда так). Подгонку можно осуществлять множеством разных функций, но я воспользуюсь следующей системой уравнений:

$$\mu = \frac{\alpha}{\alpha+\beta}$$
$$\sigma = \frac{\alpha\times\beta}{(\alpha+\beta)^2\times(\alpha+\beta+1)}$$

Из этой системы можно выразить $\alpha$ и $\beta$:

$$\alpha = \left(\frac{1-\mu}{\sigma^2} - \frac{1}{\mu}\right)\times \mu^2$$
$$\beta = \alpha\times\left(\frac{1}{\mu} - 1\right)$$

```{r}
mu <- mean(chekhov$average[chekhov$word == "не"])
var <- var(chekhov$average[chekhov$word == "не"])
alpha0 <- ((1 - mu) / var - 1 / mu) * mu ^ 2
beta0 <- alpha0 * (1 / mu - 1)
alpha0
beta0
```

Посмотрим, насколько хорошо, получившееся распределение подходит к нашим данным:
```{r}
x <- seq(0, 0.1, length = 1000)
estimation <- data_frame(
  x = x,
  density = c(dbeta(x, shape1 = alpha0, shape2 = beta0)))

chekhov %>% 
  filter(word == "не") %>% 
  select(trunc_titles, word, average) %>% 
  ggplot(aes(average)) +
  geom_density(fill = "lightblue")+
  geom_line(data = estimation, aes(x, density))+
  theme_bw()+
  labs(title = 'Частотность слова "не" на основе 305 рассказов А. Чехова',
       subtitle = "черной линией показано бета распределение с α = 5.283022 и β = 231.6328")
```

Полученное распределение можно использовать как априорное распределение для апдейта значений из каждого рассказа. Этот трюк и называется эмпирическая байесовская оценка.


