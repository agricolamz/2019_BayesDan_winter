---
title: "2. Байесовский вывод"
author: "Г. Мороз"
editor_options: 
  chunk_output_type: console
---

```{r child = 'preamble.Rmd'}
```

## 1. Байесовский вывод

### 1.1 Нотация

В байесовском подоходе статистический вывод описывается формулой Байеса

$$P(θ|Data) = \frac{P(Data|θ)\times P(θ)}{P(Data)}$$

* $P(θ|Data)$ --- апостериорная вероятность (posterior)
* $P(Data|θ)$ --- функция правдоподобия (likelihood)
* $P(θ)$ ---  априорная вероятность (prior)
* $P(Data)$ --- нормализующий делитель

В литературе можно еще встретить такую запись:

$$P(θ|Data) \propto P(Data|θ)\times P(θ)$$


## 2. Категориальные данные 

[В датасете c грибами](https://github.com/agricolamz/2019_BayesDan_winter/blob/master/datasets/mushrooms.csv?raw=true) (взят c [kaggle](https://www.kaggle.com/uciml/mushroom-classification)) представлено следующее распределение по месту обитания:

```{r}
df <- read_csv("https://github.com/agricolamz/2019_BayesDan_winter/blob/master/datasets/mushrooms.csv?raw=true")
df %>% 
  count(class, habitat) %>% 
  group_by(class) %>% 
  mutate(prop = n/sum(n)) %>% 
  ggplot(aes(class, prop, fill = habitat, label = round(prop, 3)))+
  geom_col()+
  geom_text(position = position_stack(vjust = 0.5), color = "white")
```

Мы нашли некоторый новый вид грибов на лужайке (`grasses`). Какой это может быть гриб: съедобный или ядовитый? У нас нет никаких идей, почему бы нам отдать предпочтения той или иной гипотезе, так что будем использовать неинформативное априорное распределение:

```{r}
data_frame(model = c("edible", "poisonous"),
           prior = 0.5,
           likelihood = c(0.335, 0.189),
           product = prior*likelihood,
           posterior = product/sum(product))
```

Вот мы и сделали байесовский апдейт. Теперь апостериорное распределение, которые мы получили на предыдущем шаге, мы можем использовать в новом апдейте. Допустим, мы опять нашли этот же вид гриба, но в этот раз в лесу (`woods`).

```{r}
data_frame(model = c("edible", "poisonous"),
           prior = c(0.639, 0.361),
           likelihood = c(0.447, 0.324),
           product = prior*likelihood,
           posterior = product/sum(product))
```

### 2.1


## 3. Биномиальные данные

Биномиальные данные возникают, когда нас интересует доля успехов в какой-то серии эксперементов Бернулли.

### 3.1  Биномиальное распределение

Биномиальное распределение --- распределение количетсва успехов эксперементов Бернулли из *n* попыток с вероятностью успеха *p*.

$$P(k | n, p) = \frac{n!}{k!(n-k)!} \times p^k \times (1-p)^{n-k} =  {n \choose k} \times p^k \times (1-p)^{n-k}$$ 
$$ 0 \leq p \leq 1; n, k > 0$$

```{r}
data_frame(x = 0:50,
           density = dbinom(x = x, size = 50, prob = 0.16)) %>% 
  ggplot(aes(x, density))+
  geom_point()+
  geom_line()+
  labs(title = "Биномиальное распределение p = 0.16, n = 50")
```

### 3.2 Бета распределение

$$P(x; α, β) = \frac{x^{α-1}\times (1-x)^{β-1}}{B(α, β)}; 0 \leq x \leq 1; α, β > 0$$

Бета функция:

$$Β(α, β) = \frac{Γ(α)\times Γ(β)}{Γ(α+β)} = \frac{(α-1)!(β-1)!}{(α+β-1)!} $$


```{r}
data_frame(x = seq(0, 1, length.out = 51),
           density = dbeta(x = x, shape1 = 8, shape2 = 42)) %>% 
  ggplot(aes(x, density))+
  geom_point()+
  geom_line()+
  labs(title = "Бета распределение α = 8, β = 42")
```

Можно поиграть с разными параметрами:

```{r, eval = FALSE}
shiny::runGitHub("agricolamz/beta_distribution_shiny") 
```

$$\mu = \frac{\alpha}{\alpha+\beta}$$

$$\sigma = \frac{\alpha\times\beta}{(\alpha+\beta)^2\times(\alpha+\beta+1)}$$


### 3.3 Байесовский апдейт биномиальных данных

$$Beta_{post}(\alpha_{post}, \beta_{post}) = Beta(\alpha_{prior}+\alpha_{data}, \beta_{prior}+\beta_{data}),$$
где $Beta$ --- это бета распределение

```{r, eval = FALSE}
shiny::runGitHub("agricolamz/bayes_for_binomial_app") 
```

## 4. Непрерывные данные
### 4.1 Байесовский апдейт нормального распределения
